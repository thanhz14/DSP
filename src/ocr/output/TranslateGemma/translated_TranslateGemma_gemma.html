<html><head><meta charset='UTF-8'><title>Gemma Translated TranslateGemma</title><script>window.MathJax = {tex: {inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true}};</script><script id='MathJax-script' async src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'></script>
    <style>
        body { font-family: 'Times New Roman', serif; line-height: 1.6; max-width: 900px; margin: 0 auto; padding: 20px; background: #e0e0e0; }
        .paper-page { background: white; padding: 60px; box-shadow: 0 0 15px rgba(0,0,0,0.2); margin-bottom: 30px; position: relative; min-height: 1100px; }
        .page-number { position: absolute; top: 20px; right: 20px; font-size: 12px; color: #ccc; }
        .doc_title { font-size: 26px; font-weight: bold; text-align: center; margin-bottom: 25px; }
        .paragraph_title { font-size: 18px; font-weight: bold; margin-top: 20px; border-bottom: 1px solid #eee; }
        .figure_title, .table_caption { font-size: 13px; font-weight: bold; margin: 10px 0; font-style: italic; color: #444; }
        .abstract { font-style: italic; margin: 20px 40px; text-align: justify; border-left: 4px solid #ddd; padding: 10px; background: #fdfdfd; }
        .text { text-align: justify; margin-bottom: 10px; text-indent: 1.5em; }
        .reference_content, .footnote { font-size: 12px; margin-bottom: 5px; padding-left: 25px; text-indent: -25px; }
        img { max-width: 100%; height: auto; }
    </style>
    </head><body><div class="paper-page" id="page-0">
<div class="page-number">Trang 1</div>
<p class="header_image"></p>
<h1 class="doc_title">TranslateGemma Technical Report</h1>
<p class="text">Google Translate Research Team</p>
<div class="abstract">Chúng tôi giới thiệu TranslateGemma, một bộ mô hình dịch máy mã nguồn mở dựa trên các mô hình nền Gemma 3. Để nâng cao khả năng dịch đa ngôn ngữ vốn có của Gemma 3, chúng tôi sử dụng quy trình tinh chỉnh hai giai đoạn. Đầu tiên, chúng tôi thực hiện tinh chỉnh có giám sát bằng cách sử dụng một hỗn hợp phong phú của dữ liệu song ngữ lớn, chất lượng cao, được tạo ra thông qua các mô hình tiên tiến và dữ liệu song ngữ được dịch bởi con người. Sau đó, chúng tôi thực hiện giai đoạn học tăng cường, trong đó chúng tôi tối ưu hóa chất lượng dịch bằng cách sử dụng một tập hợp các mô hình phần thưởng, bao gồm MetricX-QE và AutoMQM, nhằm mục tiêu cải thiện chất lượng dịch. Chúng tôi chứng minh hiệu quả của TranslateGemma thông qua đánh giá của con người trên bộ dữ liệu thử nghiệm WMT25 trên 10 cặp ngôn ngữ và thông qua đánh giá tự động trên bộ tham chiếu WMT24++ trên 55 cặp ngôn ngữ. Các chỉ số tự động cho thấy sự cải thiện nhất quán và đáng kể so với các mô hình Gemma 3 cơ bản trên tất cả các kích thước. Đặc biệt, các mô hình TranslateGemma nhỏ hơn thường đạt được hiệu suất tương đương với các mô hình cơ bản lớn hơn, mang lại hiệu quả tốt hơn. Chúng tôi cũng cho thấy rằng các mô hình TranslateGemma vẫn giữ được khả năng đa phương thức mạnh mẽ, với hiệu suất được cải thiện trên bộ tham chiếu dịch hình ảnh Vistra. Việc phát hành các mô hình TranslateGemma mã nguồn mở nhằm cung cấp cho cộng đồng nghiên cứu các công cụ mạnh mẽ và linh hoạt cho dịch máy.</div>
<h2 class="paragraph_title">1. Introduction</h2>
<p class="text"></p>
<p class="text">Trong một thế giới ngày càng kết nối, dịch thuật tự động (MT) đóng vai trò quan trọng trong việc phá vỡ rào cản ngôn ngữ, tạo điều kiện cho giao tiếp toàn cầu và mở rộng khả năng tiếp cận thông tin. Sự phát triển của các mô hình ngôn ngữ lớn (LLMs) đã góp phần đáng kể vào sự tiến bộ của công nghệ dịch thuật tự động. Tuy nhiên, sự tiến bộ này được hưởng lợi rất nhiều từ việc có các mô hình mạnh mẽ, mở, cho phép tính minh bạch, khả năng tái tạo và đổi mới dựa trên cộng đồng.</p>
<p class="text">Hơn nữa, TranslateGemma vẫn giữ được các khả năng đa phương thức vốn có của mô hình Gemma 3 ban đầu. Các thử nghiệm của chúng tôi trên tập dữ liệu Vistra (Salesky et al., 2024) cho thấy rằng những cải tiến trong dịch thuật văn bản cũng có tác động tích cực đến hiệu suất dịch hình ảnh, cho thấy tính linh hoạt của mô hình. Chúng tôi tin rằng việc phát hành TranslateGemma sẽ cung cấp một nguồn tài liệu quý giá cho các nhà nghiên cứu và chuyên gia trong lĩnh vực dịch thuật máy.</p>
<p class="text">Để đạt được mục tiêu này, chúng tôi giới thiệu TranslateGemma, một phiên bản mở của mô hình nền Gemma 3 (Gemma Team, 2025), được thiết kế đặc biệt cho dịch máy. Mặc dù Gemma 3 đã là một mô hình ngôn ngữ lớn đa ngôn ngữ mạnh mẽ, TranslateGemma đã được tinh chỉnh thêm để mang lại chất lượng dịch vượt trội. Sự cải thiện này đạt được thông qua một quy trình hai giai đoạn: Tinh chỉnh có giám sát (SFT) trên một tập dữ liệu song ngữ đa dạng (Phần 3) và Học tăng cường (RL) từ phản hồi của con người và mô hình (Phần 4).</p>
<h2 class="paragraph_title">2. Training data</h2>
<p class="text">Chúng tôi sử dụng hai loại dữ liệu để huấn luyện các mô hình, phần lớn dữ liệu này được chia sẻ giữa giai đoạn SFT và RL.</p>
<h2 class="paragraph_title">2.1. Synthetic Gemini-Generated Translation Data</h2>
<p class="text">Phương pháp SFT của chúng tôi kết hợp các văn bản dịch thuật bằng con người và văn bản được tạo ra bằng cách tổng hợp, được lựa chọn cẩn thận để cải thiện chất lượng dịch mà không ảnh hưởng đến khả năng tổng quát của mô hình. Giai đoạn RL sử dụng sự kết hợp của các mô hình phần thưởng được thiết kế để tối ưu hóa chất lượng dịch. Chúng tôi chứng minh hiệu quả của TranslateGemma trên các bộ dữ liệu WMT25 và WMT24++, cho thấy sự cải thiện đáng kể trên 55 cặp ngôn ngữ.</p>
<p class="text">Mục tiêu của chúng tôi là tạo ra dữ liệu tổng hợp chất lượng cao cho mỗi ngôn ngữ, vì điều này đã được chứng minh là hiệu quả.</p>
<p class="footnote">Corresponding author(s): vilar@google.com. See Contributions section for full author list. © 2026 Google. All rights reserved</p>
</div>
<div class="paper-page" id="page-1">
<div class="page-number">Trang 2</div>
<p class="text">để cải thiện đáng kể chất lượng dịch (Finkelstein et al., 2024). Chúng tôi sử dụng bộ dữ liệu MADLAD-400 (Kudugunta et al., 2023) làm nguồn dữ liệu đơn ngôn ngữ.</p>
<p class="text"></p>
<p class="text">Chúng tôi hướng tới việc tạo ra tối đa 10.000 ví dụ tổng hợp cho mỗi cặp ngôn ngữ. Để chọn các câu gốc có khả năng được hưởng lợi nhiều nhất từ việc tạo dữ liệu tổng hợp, chúng tôi trước tiên phân loại các đoạn văn gốc theo độ dài. Sau đó, chúng tôi lấy mẫu từ mỗi nhóm để có được 1 triệu đoạn văn gốc cho mỗi cặp ngôn ngữ mà chúng tôi muốn tạo dữ liệu tổng hợp. Tiếp theo, chúng tôi thực hiện một bước lọc sơ bộ trên các đoạn văn gốc này, trong đó chúng tôi lấy 2 mẫu từ Gemini 2.5 Flash, một lần sử dụng giải mã "greedily" và một lần lấy mẫu với nhiệt độ 1.0, và so sánh điểm số của chúng theo MetricX 24-QE (Juraska et al., 2024). Chúng tôi chọn các nguồn mà mẫu đạt được sự cải thiện lớn nhất so với giải mã "greedily". Ý tưởng đằng sau phương pháp lọc nguồn này là chúng tôi muốn chọn các nguồn sẽ được hưởng lợi nhiều nhất từ việc giải mã QE với 128 mẫu, vì vậy chúng tôi sử dụng 2 mẫu làm một ước tính chi phí thấp.</p>
<h2 class="paragraph_title">2.3. Language distribution</h2>
<p class="text">Tỷ lệ ngôn ngữ cuối cùng cho các giai đoạn SFT và RL có thể được tìm thấy trong Hình 1. Đối với RL, chúng tôi sử dụng cùng dữ liệu dịch như cho SFT, ngoại trừ GATITOS và SMOL, vốn chỉ được sử dụng trong SFT. Chúng tôi cung cấp danh sách đầy đủ các ngôn ngữ được sử dụng trong quá trình huấn luyện trong Phụ lục C.</p>
<h2 class="paragraph_title">2.4. Generic Instruction-Following Data</h2>
<p class="text">Hỗn hợp SFT của chúng tôi cũng bao gồm 30% dữ liệu hướng dẫn chung từ hỗn hợp Gemma 3 ban đầu. Mục đích của việc bao gồm dữ liệu này là để ngăn mô hình bị quá khớp với nhiệm vụ dịch, đồng thời duy trì khả năng tuân thủ hướng dẫn chung.</p>
<p class="text">Sau quá trình lựa chọn này, đối với mỗi cặp ngôn ngữ, chúng tôi tạo ra 128 mẫu từ Gemini 2.5 Flash, và sau đó áp dụng bộ lọc MetricX 24-QE để chọn ra những mẫu tốt nhất. Chúng tôi tạo ra các bản dịch với hai độ dài khác nhau: câu đơn lẻ và đoạn văn có độ dài tối đa 512 token. Như vậy, chúng tôi hướng tới việc hỗ trợ cả bản dịch các đoạn văn riêng lẻ cũng như các văn bản dài hơn. Để tạo ra các bản dịch này, chúng tôi sử dụng cùng một hướng dẫn như đã sử dụng cho việc đào tạo tiếp (xem phần 5.2). Để tránh các vấn đề về định dạng hoặc các bản dịch sai, chúng tôi áp dụng thêm một bước lọc định dạng, cũng dựa trên Gemini 2.5 Flash. Phương pháp này được áp dụng cho tất cả các cặp ngôn ngữ được bao gồm trong WMT24++ (Deutsch et al., 2025), cùng với một bộ các cặp ngôn ngữ bổ sung, được liệt kê trong Phụ lục B.</p>
<h2 class="paragraph_title">3. Supervised Fine-Tuning</h2>
<p class="text">Đối với quá trình tinh chỉnh có giám sát (SFT), chúng tôi bắt đầu với các điểm kiểm soát (checkpoints) đã được phát hành của Gemma 3 (27B, 12B và 4B). Chúng tôi sử dụng dữ liệu song song, bao gồm cả văn bản do con người tạo và dữ liệu tổng hợp do Gemini (Gemini Team, 2025) tạo, như được mô tả trong Mục 2. Ngoài ra, chúng tôi sử dụng dữ liệu hướng dẫn chung. Chúng tôi sử dụng công cụ SFT Kauldron $ ^{1} $ để tinh chỉnh các điểm kiểm soát Gemma 3. Để tinh chỉnh, chúng tôi sử dụng trình tối ưu hóa AdaFactor (Shazeer and Stern, 2018) với tốc độ học là 0,0001 và kích thước lô là 64, chạy trong 200.000 bước. Chúng tôi cập nhật tất cả các tham số của mô hình, nhưng giữ nguyên các tham số embedding, vì các thí nghiệm ban đầu cho thấy điều này giúp cải thiện hiệu suất dịch cho các ngôn ngữ và chữ viết không được bao gồm trong bộ dữ liệu SFT.</p>
<h2 class="paragraph_title">2.2. Human-Generated Translation Data</h2>
<h2 class="paragraph_title">4. Reinforcement Learning</h2>
<p class="text">Để tăng tính đa dạng và khả năng hỗ trợ nhiều ngôn ngữ, chúng tôi cũng bao gồm dữ liệu cho một số ngôn ngữ ít tài nguyên hơn. Đối với những ngôn ngữ này, chúng tôi ưu tiên sử dụng dữ liệu song ngữ do con người tạo ra. Dữ liệu này được lấy từ các bộ dữ liệu SMOL (Caswell et al., 2025) và GATITOS (Jones et al., 2023). SMOL bao gồm 123 ngôn ngữ và GATITOS bao gồm 170 ngôn ngữ.</p>
<p class="text">Chúng tôi đã sử dụng học tăng cường dựa trên điểm kiểm tra SFT, với việc sử dụng một tập hợp các chỉ số.</p>
<p class="footnote">$ ^{1} $https://kauldron.readthedocs.io/en/latest/</p>
</div>
<div class="paper-page" id="page-2">
<div class="page-number">Trang 3</div>
<div class="chart-container" style="text-align: center;"><img src="imgs/img_in_chart_box_620_179_1055_437.jpg" alt="chart"></div>
<div class="image-container" style="text-align: center;"><img src="imgs/img_in_image_box_133_180_568_437.jpg" alt="image"></div>
<p class="figure_title" style="text-align: center;">(a) Trộn dữ liệu SFT.</p>
<p class="figure_title" style="text-align: center;">(b) Trộn dữ liệu RL.</p>
<p class="figure_title" style="text-align: center;">Hình 1 | Phân bố ngôn ngữ trong các hỗn hợp dữ liệu của TranslateGemma, được đo bằng số lượng token của mô hình.</p>
<p class="text">như các mô hình phần thưởng, để nâng cao chất lượng dịch thuật hơn nữa.</p>
<p class="text"></p>
<p class="text">Chúng tôi sử dụng các chỉ số sau như mô hình phần thưởng trong quá trình học tăng cường:</p>
<p class="text">• MetricX-24-XXL-QE (Juraska et al., 2024), là một thước đo dịch dựa trên học máy và hồi quy, tạo ra một điểm số số thực nằm trong khoảng từ 0 (tốt nhất) đến 25 (kém nhất), tương ứng với phạm vi điểm số tiêu chuẩn của các Thước đo Chất lượng Đa chiều (MQM) (Freitag et al., 2021). Điểm số MetricX đã được điều chỉnh tuyến tính, sử dụng công thức 5.0 – điểm, khi tính toán phần thưởng, để các điểm số cao hơn cho thấy chất lượng tốt hơn. Mặc dù MetricX có thể nhận nguồn, tài liệu tham khảo và giả thuyết làm đầu vào, chúng tôi đã sử dụng nó như một thước đo QE bằng cách cung cấp một tài liệu tham khảo trống.</p>
<p class="text">• Mô hình khen thưởng tổng quát, bao gồm nhiều nhiệm vụ, bao gồm suy luận, tuân theo hướng dẫn và khả năng sử dụng nhiều ngôn ngữ, được điều chỉnh từ cấu hình chung của Gemma 3 sau khi huấn luyện (Đội Gemma, 2025).</p>
<p class="text">Chúng tôi đã sử dụng các thuật toán RL được mở rộng để hỗ trợ các lợi thế ở cấp độ token, những lợi thế này được thêm vào các lợi thế được tính toán từ phần thưởng ở cấp độ chuỗi. Điều này cho phép chúng tôi sử dụng trực tiếp các tín hiệu phần thưởng chi tiết, ở cấp độ đoạn từ từ AutoMQM và Naturalness Autorater, nhằm cải thiện việc phân bổ điểm và hiệu quả đào tạo, theo hướng của Ramos et al. (2025). Hình 2 minh họa cách các phần thưởng MetricX và AutoMQM được kết hợp (tổng) trong quá trình tính toán lợi thế. Sau đó, các lợi thế đã được chuẩn hóa theo lô.</p>
<p class="text">• Gemma-AutoMQM-QE, là một mô hình AutoMQM đã được tinh chỉnh (Fernandes et al., 2023). Mô hình này được khởi tạo từ điểm kiểm soát Gemma 3-27B-IT (Gemma Team, 2025), và được huấn luyện trên dữ liệu đánh giá MQM từ WMT 2020 - WMT 2023 (Freitag et al., 2021; Lommel et al., 2014). Các trọng số MQM mặc định (Freitag et al., 2021) đã được sử dụng để tính toán phần thưởng (mức độ) từ đầu ra của AutoMQM. Tương tự như MetricX, nó không xem xét bản dịch tham khảo.</p>
<p class="text">- ChrF (Popović, 2015), một chỉ số dịch dựa trên sự trùng lặp từ vựng. Đây là mô hình đánh giá duy nhất sử dụng các tài liệu tham khảo (tạo ra). Điểm ChrF được điều chỉnh theo hệ số hai để tương đương với các chỉ số đánh giá khác.
- Naturalness Autorater, được phát triển nội bộ, sử dụng mô hình chính sách RL làm một LLM (mô hình ngôn ngữ lớn) hoạt động như một người đánh giá. Tương tự như AutoMQM, Autorater này cũng tạo ra các đánh giá ở mức câu. Autorater này được hướng dẫn để phạt các đoạn văn trong văn bản dịch máy nếu chúng không giống như được tạo ra bởi người bản xứ (dựa trên việc các lỗi về tính tự nhiên trong đầu ra không xuất phát từ đầu vào không tự nhiên).</p>
<h2 class="paragraph_title">5. Automatic Evaluation</h2>
<h2 class="paragraph_title">5.1. Text translation</h2>
<p class="text">Chúng tôi đánh giá TranslateGemma bằng MetricX 24 (Juraska et al., 2024) và CoMET22 (Rei et al.,</p>
</div>
<div class="paper-page" id="page-3">
<div class="page-number">Trang 4</div>
<div class="image-container" style="text-align: center;"><img src="imgs/img_in_image_box_228_170_972_600.jpg" alt="image"></div>
<p class="text">Ignacio Sánchez Recarte, thư ký tổng của Ủy ban Doanh nghiệp Vang Châu Âu, một tổ chức đại diện cho khoảng 7.000 nhà sản xuất rượu vang trên khắp châu Âu, không xem xét mối quan tâm của các nhà sản xuất bia. Ông đã cho biết trong một cuộc phỏng vấn với Euronews rằng, một thị trường bị thống trị bởi các tập đoàn bia đa quốc gia không thể so sánh với một thị trường chủ yếu bao gồm các nhà sản xuất nhỏ trong nước.</p>
<p class="figure_title" style="text-align: center;">Hình 2 | Minh họa cách phần thưởng ở cấp chuỗi và cấp token được kết hợp cộng vào trong quá trình tính toán lợi thế trong học tăng cường (RL). Lưu ý rằng lợi thế được tính toán từ phần thưởng ở cấp chuỗi, được hiểu là phần thưởng được phân phối đồng đều cho mỗi token.</p>
<p class="figure_title" style="text-align: center;">Bảng 1 | Kết quả đánh giá tự động bằng MetricX và CoMET22 (C22) trên WMT24++.</p>
<p class="text"></p>
<div class="table-container"><table><tr><td>Size</td><td>System</td><td>MetricX $ \downarrow $</td><td>C22 $ \uparrow $</td></tr><tr><td rowspan="2">27B</td><td>Gemma 3</td><td>4.04</td><td>83.1</td></tr><tr><td>TranslateGemma</td><td>3.09</td><td>84.4</td></tr><tr><td rowspan="2">12B</td><td>Gemma 3</td><td>4.86</td><td>81.6</td></tr><tr><td>TranslateGemma</td><td>3.60</td><td>83.5</td></tr><tr><td rowspan="2">4B</td><td>Gemma 3</td><td>6.97</td><td>77.2</td></tr><tr><td>TranslateGemma</td><td>5.32</td><td>80.1</td></tr></table></div>
<p class="text">COMET22 xác nhận xu hướng cải thiện cho mô hình TranslateGemma. Ngoài ra, điều này cho thấy rằng những cải tiến cũng ảnh hưởng đến các chỉ số không được tối ưu hóa một cách rõ ràng trong giai đoạn học tăng cường. Ví dụ, mô hình TranslateGemma 12B đạt được điểm số 83,5, tăng so với 81,6. Mô hình TranslateGemma 4B cho thấy sự tăng trưởng lớn hơn, với COMET22 tăng từ 77,2 lên 80,1.</p>
<p class="text">Hiệu quả của quy mô mô hình cũng rất rõ ràng. Như dự đoán, các mô hình lớn thường cho ra kết quả dịch tốt hơn, cả trong cả bộ TranslateGemma cơ bản và bộ TranslateGemma. Tuy nhiên, những cải tiến do quá trình tinh chỉnh TranslateGemma mang lại là, các mô hình TranslateGemma nhỏ hơn có thể đạt được hiệu suất tương đương hoặc thậm chí vượt trội so với các mô hình cơ bản lớn hơn. Đặc biệt, mô hình 12B của TranslateGemma vượt trội hơn so với mô hình Gemma 3 cơ bản 27B. Tương tự, mô hình 4B của TranslateGemma đạt được kết quả tương đương với mô hình Gemma 3 cơ bản 12B. Lợi thế về hiệu quả này cho phép dịch chất lượng cao với ít tài nguyên tính toán hơn.</p>
<p class="text">(Năm 2022). Các mô hình TranslateGemma luôn cho thấy chất lượng dịch thuật được cải thiện so với các mô hình Gemma 3 cơ bản, trên tất cả các kích thước và chỉ số được đánh giá, như được trình bày trong Bảng 1.</p>
<p class="text">Đối với mô hình có 27 tỷ tham số, phiên bản TranslateGemma đạt điểm trung bình trên MetricX là 3,09, giảm đáng kể so với điểm 4,04 của mô hình Gemma 3 cơ bản. Điều này cho thấy sự giảm khoảng 23,5%, cho thấy sự cải thiện đáng kể trong độ chính xác của bản dịch. Xu hướng tương tự cũng được quan sát thấy đối với các mô hình có kích thước khác. Mô hình TranslateGemma có 12 tỷ tham số đạt điểm MetricX là 3,60, giảm từ 4,86 của mô hình cơ bản (giảm 25,9%), trong khi mô hình TranslateGemma có 4 tỷ tham số đạt điểm 5,32, so với 6,97 của mô hình cơ bản (giảm 23,6%).</p>
<p class="text">Phân tích chi tiết hơn về điểm số của MetricX cho</p>
</div>
<div class="paper-page" id="page-4">
<div class="page-number">Trang 5</div>
<p class="figure_title" style="text-align: center;">Bảng 2 | Kết quả đánh giá tự động bằng MetricX và CoMET22 (C22) cho hiệu suất dịch hình ảnh, trên tập dữ liệu Vistra. Điểm số là trung bình của việc dịch từ tiếng Anh sang tiếng Đức, tiếng Tây Ban Nha, tiếng Nga và tiếng Trung.</p>
<p class="text">Mỗi cặp ngôn ngữ trong 55 cặp được trình bày trong Phụ lục A cho thấy rằng các cải tiến của TranslateGemma là nhất quán trên tất cả 55 cặp ngôn ngữ được đánh giá. Dưới đây là một số ví dụ về các cải tiến cụ thể cho một số ngôn ngữ:</p>
<div class="table-container"><table><tr><td>Size</td><td>System</td><td>MetricX $ \downarrow $</td><td>C22 $ \uparrow $</td></tr><tr><td rowspan="2">27B</td><td>Gemma 3</td><td>2.03</td><td>76.1</td></tr><tr><td>TranslateGemma</td><td>1.58</td><td>77.7</td></tr><tr><td rowspan="2">12B</td><td>Gemma 3</td><td>2.33</td><td>74.9</td></tr><tr><td>TranslateGemma</td><td>2.08</td><td>72.8</td></tr><tr><td rowspan="2">4B</td><td>Gemma 3</td><td>2.60</td><td>69.1</td></tr><tr><td>TranslateGemma</td><td>2.58</td><td>70.7</td></tr></table></div>
<p class="text">• Dịch từ tiếng Anh sang tiếng Đức: từ 1.63 xuống còn 1.19.</p>
<p class="text">• Dịch từ tiếng Anh sang tiếng Tây Ban Nha: từ 2,54 xuống còn 1,88</p>
<p class="text">• Từ tiếng Anh sang tiếng Hebrew: từ 3.90 xuống còn 2.72,</p>
<p class="text">• Từ tiếng Anh sang tiếng Swahili: từ 5,92 xuống còn 4,45</p>
<p class="text">• Dịch từ tiếng Anh sang tiếng Litva: từ 6.01 xuống còn 4.39</p>
<p class="text">• Dịch từ tiếng Anh sang tiếng Estonia: từ 6.40 xuống còn 4.61 và</p>
<p class="text">• Từ tiếng Anh sang tiếng Iceland: từ 8,31 xuống còn 5,69.</p>
<p class="text">Những ví dụ này làm nổi bật khả năng của mô hình trong việc xử lý nhiều loại ngôn ngữ khác nhau, cả các ngôn ngữ có nhiều tài liệu (ví dụ: tiếng Đức, tiếng Anh) và các ngôn ngữ có ít tài liệu (ví dụ: tiếng Iceland, tiếng Swahili).</p>
<p class="text">Yêu cầu để dịch đoạn văn đó. Đặc biệt, chúng tôi không bao gồm bất kỳ thông tin nào khác về đoạn văn, chẳng hạn như vị trí của nó trong hình ảnh hoặc kết quả xử lý OCR trước đó.</p>
<p class="text">Chúng tôi cũng cho rằng, với khả năng xử lý lớn hơn, mô hình 27B sẽ được hưởng lợi nhiều hơn từ lượng lớn các ngôn ngữ được sử dụng trong giai đoạn huấn luyện trước (được mô tả chi tiết trong Phụ lục C), mặc dù chúng tôi chưa có bằng chứng thực nghiệm trực tiếp để chứng minh điều này.</p>
<p class="text">Kết quả, được trình bày trong Bảng 2, cho thấy rằng TranslateGemma vẫn giữ được khả năng xử lý hình ảnh của các mô hình Gemma 3 cơ bản. Những cải tiến về chất lượng dịch mà TranslateGemma đạt được vẫn áp dụng cho nhiệm vụ này, ngoại trừ mô hình 12B được đo bằng CoMET22. Chúng tôi nhận thấy sự cải thiện đáng kể trong điểm số MetricX, khoảng 0,5 điểm đối với mô hình 27B, hoặc 0,25 điểm đối với mô hình 12B.</p>
<h2 class="paragraph_title">5.2. Prompting the Model</h2>
<p class="text">Mô hình này đã được huấn luyện bằng hướng dẫn được trình bày trong Hình 3, đây cũng là hướng dẫn mà chúng tôi đã sử dụng trong quá trình đánh giá. Chúng tôi khuyến nghị sử dụng cùng một hướng dẫn để tạo ra các bản dịch mới. Các công cụ để tự động bao bọc văn bản bằng hướng dẫn này được cung cấp trong kho lưu trữ của mô hình.</p>
<p class="text">Mô hình 4B nhỏ chỉ mang lại những cải tiến nhỏ so với mô hình cơ bản, có lẽ do khả năng xử lý hạn chế của nó.</p>
<h2 class="paragraph_title">6. Human Evaluation</h2>
<h2 class="paragraph_title">5.3. Image Translation</h2>
<p class="text">Chúng tôi thực hiện đánh giá bằng phương pháp thủ công trên một tập hợp nhỏ các hướng dẫn dịch để đo hiệu suất dịch của TranslateGemma. Chúng tôi sử dụng MQM (Freitag et al., 2021; Lommel et al., 2014), một khung đánh giá bằng phương pháp thủ công, trong đó các dịch giả chuyên nghiệp xác định các lỗi trong bản dịch, cùng với ngữ cảnh của tài liệu, và gán mức độ nghiêm trọng và loại lỗi cho mỗi lỗi. Điểm số được tính toán tự động bằng cách đếm.</p>
<p class="text">Chúng tôi sử dụng bộ tiêu chuẩn Vistra (Salesky et al., 2024) để đánh giá xem các mô hình có duy trì khả năng dịch văn bản trong hình ảnh sau các bước huấn luyện bổ sung của chúng hay không. Lưu ý rằng không sử dụng bất kỳ bộ dữ liệu huấn luyện đa phương thức nào trong các bước SFT và RL được báo cáo trong công trình này. Để đơn giản hóa quy trình đánh giá, chúng tôi chỉ chọn những hình ảnh mà, theo tham khảo, chứa một trường hợp văn bản duy nhất. Điều này dẫn đến một tập hợp 264 hình ảnh. Một ví dụ được minh họa trong Hình 4. Đầu vào cho mô hình chỉ là hình ảnh cùng với một</p>
<p class="footnote">$ ^{2} $The model release also includes an interface for image translation, similar to the one for text translation.</p>
</div>
<div class="paper-page" id="page-5">
<div class="page-number">Trang 6</div>
<div class="table-container"><table><tr><td>You are a professional {source_lang} ({src_lang_code}) to {target_lang}</td></tr><tr><td>({tgt_lang_code}) translator. Your goal is to accurately convey the meaning and nuances of the original {source_lang} text while adhering to {target_lang} grammar, vocabulary, and cultural sensitivities. Produce only the {target_lang} translation, without any additional explanations or commentary. Please translate the following {source_lang} text into {target_lang}: \n\n\n\n\n\n</td></tr></table></div>
<p class="figure_title" style="text-align: center;">Hình 3 | Gợi ý được ưu tiên khi sử dụng mô hình. "source_lang" đề cập đến tên ngôn ngữ nguồn, ví dụ: tiếng Anh, "src_lang_code" đề cập đến mã ngôn ngữ nguồn, ví dụ: en-US, "target_lang" đề cập đến ngôn ngữ đích, ví dụ: tiếng Đức, và "tgt_lang_code" đề cập đến mã ngôn ngữ đích, tức là de-DE.</p>
<div class="image-container" style="text-align: center;"><img src="imgs/img_in_image_box_124_511_579_848.jpg" alt="image"></div>
<p class="text"></p>
<p class="text">Để tránh tình trạng mệt mỏi cho người đánh giá, mỗi tài liệu trong bộ dữ liệu được cắt ngắn ở phần đoạn, với tối đa 12 câu từ nguồn, bỏ qua các tài liệu có hơn 12 câu trong đoạn đầu tiên. Tuy nhiên, đối với lĩnh vực văn học, nơi mỗi tài liệu là một chương sách, các tài liệu được chia thành các "phần" gồm 1 hoặc nhiều đoạn, lên đến giới hạn 12 câu, và mỗi phần được đánh giá riêng bởi người đánh giá. Theo Riley et al. (2024), chúng tôi sử dụng phương pháp "gán người đánh giá giả", trong đó tất cả các kết quả của hệ thống cho một tài liệu nguồn cụ thể được đánh giá bởi cùng một người đánh giá.</p>
<p class="figure_title" style="text-align: center;">Hình 4 | Ví dụ về các hình ảnh được sử dụng trong bộ kiểm tra Vistra.</p>
<p class="text">các lỗi với một hệ thống trọng số. Chúng tôi thu thập các đánh giá bằng công cụ mã nguồn mở Anthea. Chúng tôi đánh giá các mô hình trên 10 cặp ngôn ngữ, từ 3 ngôn ngữ nguồn khác nhau:</p>
<p class="text">Kết quả có thể được tìm thấy trong Bảng 3. Đối với hầu hết các cặp ngôn ngữ, đánh giá của con người xác nhận xu hướng mà chúng ta thấy trên các chỉ số tự động, với TranslateGemma vượt trội hơn đáng kể so với Gemma 3. Có hai trường hợp ngoại lệ: khi ngôn ngữ đích là tiếng Đức, cả hai mô hình đều đạt kết quả tương đương, và tiếng Nhật → tiếng Anh, trong đó TranslateGemma thực sự gặp phải sự suy giảm. Khi phân loại lỗi, chúng tôi nhận thấy rằng điều này là do dịch sai các thực thể được đặt tên, trong khi các loại lỗi khác đã được cải thiện.</p>
<p class="text">• English to German</p>
<p class="text">• Dịch từ tiếng Anh sang tiếng Trung (giản thể)</p>
<p class="text">• English to Italian</p>
<p class="text">• Dịch từ tiếng Anh sang tiếng Serbia (từ Latinh)</p>
<p class="text">• English to Korean</p>
<p class="text">• Dịch từ tiếng Anh sang tiếng Swahili (Kenya)</p>
<p class="text">• English to Marathi</p>
<p class="text">• Czech to Ukrainian</p>
<p class="text">• Czech to German</p>
<p class="text">• Japanese to English</p>
<p class="text">Những cải tiến cho TranslateGemma đặc biệt phù hợp cho các cặp ngôn ngữ có nguồn lực hạn chế. Ví dụ, khi dịch từ tiếng Anh sang tiếng Marathi, chúng ta đạt được mức cải thiện là 1,6 điểm, hoặc 1,0 điểm khi dịch từ tiếng Anh sang tiếng Swahili.</p>
<p class="text">Chúng tôi đã chọn bộ dữ liệu này để có sự kết hợp giữa các ngôn ngữ có nguồn lực cao và thấp, đồng thời bao gồm các ngôn ngữ thuộc các ngữ hệ khác nhau và hệ thống chữ viết khác nhau. Dữ liệu gốc được lấy từ nhiệm vụ dịch thuật WMT25, sử dụng các lĩnh vực văn học, tin tức và mạng xã hội. Đối với tất cả các cặp ngôn ngữ, chúng tôi đã đánh giá TranslateGemma 12B và 27B, cũng như Gemma 3 27B.</p>
<p class="footnote">$ ^{3} $https://github.com/google-research/</p>
<p class="footnote">google-research/tree/master/anthea</p>
</div>
<div class="paper-page" id="page-6">
<div class="page-number">Trang 7</div>
<p class="figure_title" style="text-align: center;">Bảng 3 | Kết quả đánh giá của con người đối với TranslateGemma và Gemma 3 theo thang đo MQM. Điểm số thấp hơn là tốt hơn.</p>
<div class="table-container"><table><tr><td></td><td colspan="2">TranslateGemma</td><td>Gemma 3</td></tr><tr><td>Language Pair</td><td>27B</td><td>12B</td><td>27B</td></tr><tr><td>English→Italian</td><td>1.8</td><td>2.0</td><td>2.5</td></tr><tr><td>English→German</td><td>2.3</td><td>3.2</td><td>2.2</td></tr><tr><td>English→Marathi</td><td>3.1</td><td>4.6</td><td>4.7</td></tr><tr><td>English→Korean</td><td>3.1</td><td>4.6</td><td>3.8</td></tr><tr><td>English→Swahili</td><td>4.2</td><td>5.2</td><td>5.2</td></tr><tr><td>Czech→Ukrainian</td><td>5.3</td><td>8.5</td><td>6.3</td></tr><tr><td>English→Chinese</td><td>6.3</td><td>8.4</td><td>7.4</td></tr><tr><td>English→Serbian</td><td>8.7</td><td>15.8</td><td>10.4</td></tr><tr><td>Czech→German</td><td>10.3</td><td>11.4</td><td>10.2</td></tr><tr><td>Japanese→English</td><td>13.4</td><td>15.7</td><td>11.6</td></tr></table></div>
<p class="text">Từ tiếng Séc sang tiếng Ukraina. Đánh giá của con người cũng xác nhận sự khác biệt về hiệu suất giữa các mô hình TranslateGemma 27B và 12B, vốn đã được thể hiện bởi các chỉ số tự động. Tuy nhiên, mô hình 12B vẫn cạnh tranh tốt với mô hình Gemma 3 lớn hơn, đặc biệt đối với các ngôn ngữ có nhiều tài liệu.</p>
<p class="text"></p>
<p class="text">Hơn nữa, chúng tôi đã chứng minh rằng các mô hình TranslateGemma vẫn giữ được khả năng đa phương thức của mô hình Gemma 3 ban đầu. Các thử nghiệm trên bộ dữ liệu Vistra cho thấy, những cải tiến trong dịch thuật văn bản cũng được áp dụng cho nhiệm vụ dịch hình ảnh, đặc biệt là đối với các mô hình 12B và 27B, mà không cần điều chỉnh đa phương thức cụ thể.</p>
<h2 class="paragraph_title">7. Conclusions</h2>
<p class="text">Trong công trình này, chúng tôi giới thiệu TranslateGemma, một loạt các mô hình mã nguồn mở dựa trên Gemma 3, được thiết kế đặc biệt cho dịch máy. Bằng cách kết hợp điều chỉnh tinh chỉnh có giám sát trên các bộ dữ liệu song ngữ chất lượng cao và đa dạng – kết hợp nguồn dữ liệu từ con người và tổng hợp – cùng với một phương pháp học tăng cường mới sử dụng một tập hợp các mô hình phần thưởng, chúng tôi đã cải thiện hiệu suất dịch trên nhiều ngôn ngữ và kích thước mô hình khác nhau (4B, 12B và 27B tham số).</p>
<p class="text">Việc phát hành các mô hình TranslateGemma đóng góp một bộ công cụ mã nguồn mở có giá trị cho cộng đồng dịch máy, thúc đẩy nghiên cứu và phát triển ứng dụng hơn nữa. Chúng tôi tin rằng các mô hình này sẽ đóng vai trò là nền tảng vững chắc cho nhiều nhiệm vụ liên quan đến dịch thuật và khuyến khích việc sử dụng và khám phá chúng.</p>
<p class="text">Kết quả đánh giá tự động của chúng tôi trên bộ dữ liệu WMT24++, bao gồm 55 cặp ngôn ngữ, cho thấy các mô hình TranslateGemma có kết quả tốt hơn so với các mô hình Gemma 3 cơ bản, cả trên MetricX và COMET22. Chúng tôi nhận thấy sự cải thiện đáng kể trên nhiều loại ngôn ngữ, bao gồm cả các ngôn ngữ có nhiều tài liệu như tiếng Đức và tiếng Tây Ban Nha, cũng như các ngôn ngữ có ít tài liệu hơn như tiếng Iceland hoặc tiếng Swahili. Một kết quả quan trọng là các mô hình TranslateGemma có hiệu quả cao hơn, trong đó các mô hình đã được tinh chỉnh nhỏ thường đạt hoặc vượt qua hiệu suất của các mô hình cơ bản lớn hơn, mang lại sự cân bằng tốt hơn giữa chất lượng và chi phí tính toán.</p>
<h2 class="paragraph_title">References</h2>
<p class="text">Isaac Caswell, Elizabeth Nielsen, Jiaming Luo, Colin Cherry, Geza Kovacs, Hadar Shemtov, Partha Talukdar, Dinesh Tewari, Baba Mamadi Diane, Djibrila Diane, Solo Farabado Cissé, Koulako Moussa Doumbouya, Edoardo Ferrante, Alessandro Guasoni, Christopher Homan, Mamadou K. Keita, Sudhamoy Deb</p>
</div>
<div class="paper-page" id="page-7">
<div class="page-number">Trang 8</div>
<p class="reference_content">Barma, Ali Kuzhuget, David Anugraha, Muhammad Ravi Shulthan Habibi, Sina Ahmadi, Anthony Munthali, Jonathan Mingfei Liu, and Jonathan Eng. 2025. SMOL: Professionally translated parallel data for 115 underrepresented languages. In Proceedings of the Tenth Conference on Machine Translation, pages 1103–1123, Suzhou, China. Association for Computational Linguistics.</p>
<p class="reference_content">Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. 2025. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities.</p>
<p class="reference_content">Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ramé, Morgane Rivière, Louis Rouillard, et al. 2025. Gemma 3 technical report.</p>
<p class="reference_content">Daniel Deutsch, Eleftheria Briakou, Isaac Rayburn Caswell, Mara Finkelstein, Rebecca Galor, Juraj Juraska, Geza Kovacs, Alison Lui, Ricardo Rei, Jason Riesa, Shruti Rijhwani, Parker Riley, Elizabeth Salesky, Firas Trabelsi, Stephanie Winkler, Biao Zhang, and Markus Freitag. 2025. WMT24++: Expanding the language coverage of WMT24 to 55 languages & dialects. In Findings of the Association for Computational Linguistics: ACL 2025, pages 12257–12284, Vienna, Austria. Association for Computational Linguistics.</p>
<p class="reference_content">Alexander Jones, Isaac Caswell, Orhan Firat, and Ishank Saxena. 2023. GATITOS: Using a new multilingual lexicon for low-resource machine translation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 371–405, Singapore. Association for Computational Linguistics.</p>
<p class="reference_content">Juraj Juraska, Daniel Deutsch, Mara Finkelstein, and Markus Freitag. 2024. MetricX-24: The Google submission to the WMT 2024 metrics shared task. In Proceedings of the Ninth Conference on Machine Translation, pages 492–504, Miami, Florida, USA. Association for Computational Linguistics.</p>
<p class="reference_content">Patrick Fernandes, Daniel Deutsch, Mara Finkelstein, Parker Riley, André Martins, Graham Neubig, Ankush Garg, Jonathan Clark, Markus Freitag, and Orhan Firat. 2023. The devil is in the errors: Leveraging large language models for fine-grained machine translation evaluation. In Proceedings of the Eighth Conference on Machine Translation, pages 1066–1083, Singapore. Association for Computational Linguistics.</p>
<p class="reference_content">Sneha Kudugunta, Isaac Caswell, Biao Zhang, Xavier Garcia, Derrick Xin, Aditya Kusupati, Romi Stella, Ankur Bapna, and Orhan Firat. 2023. Madlad-400: A multilingual and document-level large audited dataset. Advances in Neural Information Processing Systems, 36:67284–67296.</p>
<p class="reference_content">Mara Finkelstein, David Vilar, and Markus Freitag. 2024. Introducing the NewsPaLM MBR and QE dataset: LLM-generated high-quality parallel data outperforms traditional web-crawled data. In Proceedings of the Ninth Conference on Machine Translation, pages 1355–1372, Miami, Florida, USA. Association for Computational Linguistics.</p>
<p class="reference_content">Arle Richard Lommel, Aljoscha Burchardt, and Hans Uszkoreit. 2014. Multidimensional quality metrics (mqm): A framework for declaring and describing translation quality metrics. Tradumàtica: tecnologies de la traducció, (12):455–463.</p>
<p class="reference_content">Markus Freitag, George Foster, David Grangier, Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey. 2021. Experts, errors, and context: A large-scale study of human evaluation for machine translation. Transactions of the Association for Computational Linguistics, 9:1460–1474.</p>
<p class="reference_content">Maja Popović. 2015. chrF: character n-gram F-score for automatic MT evaluation. In Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 392–395, Lisbon, Portugal. Association for Computational Linguistics.</p>
<p class="reference_content">Gemini Team, Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen</p>
<p class="reference_content">Miguel Moura Ramos, Tomás Almeida, Daniel Vareta, Filipe Azevedo, Sweta Agrawal, Patrick</p>
</div>
<div class="paper-page" id="page-8">
<div class="page-number">Trang 9</div>
<h2 class="paragraph_title">Contributions</h2>
<p class="text">Fernandes và André F. T. Martins. 2025. Tối ưu hóa phần thưởng chi tiết cho dịch máy bằng cách sử dụng bản đồ mức độ nghiêm trọng của lỗi.</p>
<h2 class="paragraph_title">Core Contributors</h2>
<p class="text">Mara Finkelstein
Isaac Caswell
Tobias Domhan
Jan-Thorsten Peter
Juraj Juraska
Parker Riley
Daniel Deutsch
Geza Kovács</p>
<p class="text">Ricardo Rei, José G. C. de Souza, Duarte Alves, Chrysoula Zerva, Ana C Farinha, Taisiya Glushkova, Alon Lavie, Luisa Coheur, và André F. T. Martins. 2022. COMET-22: Bài dự thi cho nhiệm vụ đánh giá chung trong UnbabelIST 2022. Trong Hội nghị về Dịch máy lần thứ bảy (WMT), trang 578–585, Abu Dhabi, Các Tiểu vương quốc Ả Rập Thống nhất (Hỗn hợp). Hiệp hội Ngôn ngữ Tính toán.</p>
<h2 class="paragraph_title">Lead</h2>
<p class="text">Parker Riley, Daniel Deutsch, George Foster, Viresh Ratnakar, Ali Dabirmoghaddam và Markus Freitag. 2024. Tìm kiếm đánh giá của con người có thể tái lập thông qua xác suất xếp hạng ổn định. Trong Hội nghị Liên đoàn Khoa học Ngôn ngữ Tính toán năm 2024 – Chi nhánh Bắc Mỹ: Công nghệ Ngôn ngữ (Tập 1: Bài viết dài), trang 4908–4919, Mexico City, Mexico. Liên đoàn Khoa học Ngôn ngữ Tính toán.</p>
<p class="text">David Vilar
Markus Freitag</p>
<h2 class="paragraph_title">Contributors</h2>
<p class="text">Cole Dilanni
Colin Cherry
Eleftheria Briakou
Elizabeth Nielsen
Jiaming Luo
Kat Black
Ryan Mullins
Sweta Agrawal
Wenda Xu</p>
<p class="text">Elizabeth Salesky, Philipp Koehn và Matt Post. 2024. Đánh giá hiệu quả dịch thuật dựa trên hình ảnh trong các văn bản tự nhiên. Trong Hội nghị về Dịch thuật Máy lần thứ 9, trang 1167–1182, Miami, Florida, Hoa Kỳ. Hiệp hội Ngôn ngữ Tính toán.</p>
<p class="text">Noam Shazeer và Mitchell Stern. 2018. Adafactor: Tốc độ học thích ứng với chi phí bộ nhớ tuyến tính. Trong Hội nghị Quốc tế về Học máy, trang 4596–4604. PMLR.</p>
<h2 class="paragraph_title">Support</h2>
<p class="text">Erin Kats
Stephane Jaskiewicz</p>
<p class="footnote">$ ^{*} $Now at Anthropic.</p>
</div>
<div class="paper-page" id="page-9">
<div class="page-number">Trang 10</div>
<h2 class="paragraph_title">A. Automatic metrics per language</h2>
<p class="figure_title" style="text-align: center;">Bảng 4 | So sánh hiệu suất của các mô hình TranslateGemma (GT) với các mô hình Gemma cơ bản (G3) cho mỗi cặp ngôn ngữ trong bộ dữ liệu WMT24++ bằng MetricX.</p>
<div class="table-container"><table><tr><td rowspan="2"></td><td colspan="3">TranslateGemma</td><td colspan="3">Gemma 3</td></tr><tr><td>27B</td><td>12B</td><td>4B</td><td>27B</td><td>12B</td><td>4B</td></tr><tr><td>en→ar_EG</td><td>2.54</td><td>2.78</td><td>3.57</td><td>3.32</td><td>3.70</td><td>4.60</td></tr><tr><td>en→ar_SA</td><td>2.42</td><td>2.66</td><td>3.43</td><td>3.19</td><td>3.64</td><td>4.49</td></tr><tr><td>en→bg_BG</td><td>2.80</td><td>3.25</td><td>4.30</td><td>3.90</td><td>4.47</td><td>5.81</td></tr><tr><td>en→bn_IN</td><td>1.88</td><td>2.12</td><td>2.92</td><td>2.56</td><td>2.87</td><td>3.86</td></tr><tr><td>en→ca_ES</td><td>3.18</td><td>3.58</td><td>5.20</td><td>4.07</td><td>4.89</td><td>6.97</td></tr><tr><td>en→cs_CZ</td><td>3.48</td><td>4.03</td><td>5.41</td><td>4.62</td><td>5.32</td><td>7.47</td></tr><tr><td>en→da_DK</td><td>2.11</td><td>2.45</td><td>3.25</td><td>3.00</td><td>3.36</td><td>4.40</td></tr><tr><td>en→de_DE</td><td>1.19</td><td>1.36</td><td>1.93</td><td>1.63</td><td>1.93</td><td>2.72</td></tr><tr><td>en→el_GR</td><td>2.57</td><td>3.34</td><td>4.66</td><td>3.73</td><td>4.34</td><td>6.31</td></tr><tr><td>en→es_MX</td><td>1.88</td><td>2.06</td><td>2.51</td><td>2.54</td><td>2.75</td><td>3.35</td></tr><tr><td>en→et_EE</td><td>4.61</td><td>6.15</td><td>11.03</td><td>6.40</td><td>8.89</td><td>14.78</td></tr><tr><td>en→fa_IR</td><td>1.99</td><td>2.28</td><td>3.34</td><td>2.98</td><td>3.41</td><td>4.77</td></tr><tr><td>en→fi_FI</td><td>3.19</td><td>3.77</td><td>5.68</td><td>4.19</td><td>5.11</td><td>7.54</td></tr><tr><td>en→fil_PH</td><td>2.98</td><td>3.17</td><td>4.20</td><td>3.62</td><td>4.03</td><td>5.22</td></tr><tr><td>en→fr_CA</td><td>2.21</td><td>2.37</td><td>2.92</td><td>2.78</td><td>2.97</td><td>3.76</td></tr><tr><td>en→fr_FR</td><td>2.19</td><td>2.44</td><td>2.97</td><td>2.78</td><td>3.01</td><td>3.90</td></tr><tr><td>en→gu_IN</td><td>4.69</td><td>4.93</td><td>6.32</td><td>5.27</td><td>5.79</td><td>7.67</td></tr><tr><td>en→he_IL</td><td>2.72</td><td>3.12</td><td>4.99</td><td>3.90</td><td>4.41</td><td>6.70</td></tr><tr><td>en→hi_IN</td><td>3.52</td><td>3.69</td><td>4.33</td><td>4.11</td><td>4.36</td><td>5.03</td></tr><tr><td>en→hr_HR</td><td>2.05</td><td>2.31</td><td>3.17</td><td>2.62</td><td>3.08</td><td>4.26</td></tr><tr><td>en→hu_HU</td><td>4.24</td><td>5.00</td><td>7.84</td><td>5.51</td><td>6.79</td><td>10.75</td></tr><tr><td>en→id_ID</td><td>2.07</td><td>2.17</td><td>2.63</td><td>2.72</td><td>2.84</td><td>3.27</td></tr><tr><td>en→is_IS</td><td>5.69</td><td>7.93</td><td>15.54</td><td>8.31</td><td>12.16</td><td>19.22</td></tr><tr><td>en→it_IT</td><td>1.88</td><td>2.17</td><td>2.64</td><td>2.60</td><td>2.84</td><td>3.60</td></tr><tr><td>en→ja_JP</td><td>3.53</td><td>3.82</td><td>4.44</td><td>4.11</td><td>4.30</td><td>5.09</td></tr><tr><td>en→kn_IN</td><td>4.18</td><td>4.78</td><td>7.11</td><td>5.09</td><td>6.82</td><td>10.48</td></tr><tr><td>en→ko_KR</td><td>2.81</td><td>2.97</td><td>3.93</td><td>3.43</td><td>3.79</td><td>4.72</td></tr><tr><td>en→lt_LT</td><td>4.39</td><td>5.41</td><td>9.58</td><td>6.01</td><td>7.71</td><td>13.39</td></tr><tr><td>en→lv_LV</td><td>5.69</td><td>7.22</td><td>12.12</td><td>7.55</td><td>9.90</td><td>15.75</td></tr><tr><td>en→ml_IN</td><td>3.64</td><td>4.30</td><td>7.33</td><td>4.77</td><td>6.84</td><td>11.89</td></tr><tr><td>en→mr_IN</td><td>3.17</td><td>3.47</td><td>4.30</td><td>4.11</td><td>4.60</td><td>5.64</td></tr><tr><td>en→nl_NL</td><td>1.67</td><td>2.01</td><td>2.84</td><td>2.48</td><td>2.82</td><td>3.87</td></tr><tr><td>en→no_NO</td><td>2.09</td><td>2.38</td><td>3.26</td><td>2.94</td><td>3.17</td><td>4.23</td></tr><tr><td>en→pa_IN</td><td>3.67</td><td>4.44</td><td>5.53</td><td>4.40</td><td>5.99</td><td>11.20</td></tr><tr><td>en→pl_PL</td><td>4.14</td><td>4.58</td><td>5.64</td><td>5.17</td><td>5.64</td><td>7.07</td></tr><tr><td>en→pt_BR</td><td>2.13</td><td>2.36</td><td>2.93</td><td>2.90</td><td>3.15</td><td>3.77</td></tr><tr><td>en→pt_PT</td><td>2.55</td><td>2.68</td><td>3.09</td><td>3.39</td><td>3.78</td><td>4.13</td></tr><tr><td>en→ro_RO</td><td>2.86</td><td>3.25</td><td>4.18</td><td>3.99</td><td>4.39</td><td>5.70</td></tr><tr><td>en→ru_RU</td><td>2.18</td><td>2.48</td><td>3.25</td><td>3.01</td><td>3.39</td><td>4.54</td></tr><tr><td>en→sk_SK</td><td>3.81</td><td>4.54</td><td>6.70</td><td>5.04</td><td>5.86</td><td>9.17</td></tr><tr><td>en→sl_SI</td><td>3.55</td><td>4.24</td><td>7.12</td><td>4.56</td><td>5.73</td><td>9.39</td></tr><tr><td>en→sr_RS</td><td>2.78</td><td>2.68</td><td>5.66</td><td>3.75</td><td>3.76</td><td>6.94</td></tr><tr><td>en→sv_SE</td><td>2.00</td><td>2.31</td><td>3.14</td><td>2.73</td><td>3.06</td><td>4.14</td></tr><tr><td>en→sw_KE</td><td>4.45</td><td>5.36</td><td>10.65</td><td>5.92</td><td>7.90</td><td>14.05</td></tr><tr><td>en→sw_TZ</td><td>4.30</td><td>5.25</td><td>10.30</td><td>5.73</td><td>7.85</td><td>13.89</td></tr><tr><td>en→ta_IN</td><td>2.87</td><td>2.98</td><td>3.90</td><td>3.53</td><td>3.83</td><td>5.04</td></tr><tr><td>en→te_IN</td><td>3.76</td><td>3.97</td><td>4.83</td><td>4.41</td><td>4.74</td><td>5.76</td></tr><tr><td>en→th_TH</td><td>2.33</td><td>2.66</td><td>3.49</td><td>2.96</td><td>3.19</td><td>4.14</td></tr><tr><td>en→tr_TR</td><td>4.18</td><td>4.64</td><td>6.17</td><td>5.32</td><td>6.02</td><td>8.03</td></tr><tr><td>en→uk_UA</td><td>2.98</td><td>3.29</td><td>4.16</td><td>3.79</td><td>4.28</td><td>5.40</td></tr><tr><td>en→ur_PK</td><td>3.12</td><td>3.59</td><td>5.67</td><td>3.86</td><td>4.86</td><td>7.80</td></tr><tr><td>en→vi_VN</td><td>1.97</td><td>2.20</td><td>2.87</td><td>2.56</td><td>2.88</td><td>3.62</td></tr><tr><td>en→zh_CN</td><td>1.86</td><td>2.07</td><td>2.66</td><td>2.47</td><td>2.61</td><td>3.27</td></tr><tr><td>en→zh_TW</td><td>2.04</td><td>2.21</td><td>2.77</td><td>2.63</td><td>2.80</td><td>3.62</td></tr><tr><td>en→zu_ZA</td><td>6.99</td><td>10.73</td><td>18.29</td><td>9.05</td><td>14.80</td><td>21.52</td></tr><tr><td></td><td>27B</td><td>12B</td><td>4B</td><td>27B</td><td>12B</td><td>4B</td></tr><tr><td colspan="3">TranslateGemma</td><td colspan="4">Gemma 3</td></tr></table></div>
</div>
<div class="paper-page" id="page-10">
<div class="page-number">Trang 11</div>
<h2 class="paragraph_title">B. Additional synthetic data languages</h2>
<p class="text">Đối với các ngôn ngữ sau, chúng tôi đã tạo ra dữ liệu tổng hợp, ngoài các ngôn ngữ được bao gồm trong WMT24++:</p>
<p class="text">Tiếng Anh - tiếng Armenia, tiếng Anh - tiếng Hawaii, tiếng Anh - tiếng Frisian phương Tây, tiếng Anh - tiếng Corsica, tiếng Anh - tiếng Hmong, tiếng Anh - tiếng Malta, tiếng Anh - tiếng Tajikistan, tiếng Anh - tiếng Samoa, tiếng Anh - tiếng Macedonia, tiếng Anh - tiếng Mông Cổ, tiếng Anh - tiếng Galicia, tiếng Anh - tiếng Albania, tiếng Anh - tiếng Uzbekistan, tiếng Anh - tiếng Uyghur, tiếng Anh - tiếng Belarus, tiếng Anh - tiếng Sinhala, tiếng Anh - tiếng Basque, tiếng Anh - tiếng Creole Haiti, tiếng Anh - tiếng Bosnia, tiếng Anh - tiếng Kyrgyz, tiếng Anh - tiếng Kazakhstan, tiếng Anh - tiếng Khmer, tiếng Anh - tiếng Gaelic Scotland, tiếng Anh - tiếng Lào, tiếng Anh - tiếng Ireland, tiếng Anh - tiếng Luxembourg, tiếng Anh - tiếng Myanmar, tiếng Anh - tiếng Sundanese, tiếng Anh - tiếng Javanese, tiếng Anh - tiếng Malay.</p>
<h2 class="paragraph_title">C. Full list of languages for SFT</h2>
<p class="text">Bảng 5 cho thấy các ngôn ngữ được ghép cặp với tiếng Anh theo cả hai hướng, bảng 6 cho thấy các ngôn ngữ được ghép cặp với tiếng Anh như ngôn ngữ nguồn, và bảng 7 cho thấy các cặp ngôn ngữ không liên quan đến tiếng Anh. Cùng nhau, ba bảng này cung cấp đầy đủ thông tin về phạm vi ngôn ngữ của dữ liệu SFT được sử dụng cho TranslateGemma.</p>
</div>
<div class="paper-page" id="page-11">
<div class="page-number">Trang 12</div>
<p class="figure_title" style="text-align: center;">Bảng 5 | Các ngôn ngữ được sử dụng song song với tiếng Anh theo cả hai hướng.</p>
<div class="table-container"><table><tr><td>Abkhaz (ab)</td><td>Acehnese (ace)</td><td>Acholi (ach)</td><td>Afar (aa)</td></tr><tr><td>Afrikaans (af)</td><td>Ahirani (ahr)</td><td>Alur (alz)</td><td>Amharic (am)</td></tr><tr><td>Assamese (as)</td><td>Assyrian Neo-Aramaic (aii)</td><td>Avar (av)</td><td>Awadhi (awa)</td></tr><tr><td>Aymara (ay)</td><td>Badaga (bfq)</td><td>Bagheli (bfy)</td><td>Bagri (bgq)</td></tr><tr><td>Balinese (ban)</td><td>Baluchi (bal)</td><td>Bambara (bm)</td><td>Banjar (Arabic script) (bjn-Arab)</td></tr><tr><td>Banjar (bjn)</td><td>Baoul00e9 (bci)</td><td>Bashkir (ba)</td><td>Batak Karo (btx)</td></tr><tr><td>Batak Simalungun (bts)</td><td>Batak Toba (bbc)</td><td>Bemba (Zambia) (bem)</td><td>Betawi (bew)</td></tr><tr><td>Bhojpuri (bho)</td><td>Bikol (bik)</td><td>Bodo (India) (brx)</td><td>Braj (bra)</td></tr><tr><td>Breton (br)</td><td>Buginese (bug)</td><td>Bundeli (bns)</td><td>Buryat (bua)</td></tr><tr><td>Cantonese (yue)</td><td>Chakma (Latin script) (ccp-Latn)</td><td>Chamorro (ch)</td><td>Chechen (ce)</td></tr><tr><td>Chhattisgarhi (hne)</td><td>Chichewa (ny)</td><td>Chinese (zh-CN)</td><td>Chittagonian (ctg)</td></tr><tr><td>Chuukese (chk)</td><td>Chuvash (cv)</td><td>Crimean Tatar (Cyrillic script) (crh)</td><td>Crimean Tatar (Latin script) (crh-Latn)</td></tr><tr><td>Dari (fa-AF)</td><td>Dhivehi (dv)</td><td>Dhundari (dhd)</td><td>Dinka (din)</td></tr><tr><td>Dogri (doi)</td><td>Dombe (dov)</td><td>Dutch (nl)</td><td>Dyula (dyu)</td></tr><tr><td>Dzongkha (dz)</td><td>East Circassian (kbd)</td><td>Eastern Huasteca Nahuatl (nhe)</td><td>Efik (efi)</td></tr><tr><td>Egyptian Arabic (arz)</td><td>Ewe (ee)</td><td>Faroese (fo)</td><td>Fijian (fj)</td></tr><tr><td>Fon (fon)</td><td>French (fr)</td><td>Friulian (fur)</td><td>Fulani (ff)</td></tr><tr><td>Ga (gaa)</td><td>Garo (Latin script) (grt-Latn)</td><td>German (de)</td><td>Goan Konkani (gom)</td></tr><tr><td>Guarani (gn)</td><td>Hakha Chin (cnh)</td><td>Hausa (ha)</td><td>Hiligaynon (hil)</td></tr><tr><td>Hindi (hi)</td><td>Ho (Warang Chiti script) (hoc-Wara)</td><td>Hunsrik (hrx)</td><td>Iban (iba)</td></tr><tr><td>Igbo (ig)</td><td>Ilocano (ilo)</td><td>Indonesian (id)</td><td>Inuktut (Syllabics) (iu)</td></tr><tr><td>Isoko (iso)</td><td>Italian (it)</td><td>Jamaican Patois (jam)</td><td>Japanese (ja)</td></tr><tr><td>Jingpo (kac)</td><td>K&#x27;iche&#x27; (quc)</td><td>Kalaalisut (kl)</td><td>Kangri (xnr)</td></tr><tr><td>Kanuri (kr)</td><td>Kapampangan (pam)</td><td>Karakalpak (kaa)</td><td>Kashmiri (Devanagari script) (ks-Deva)</td></tr><tr><td>Kashmiri (ks)</td><td>Kedah Malay (meo)</td><td>Khasi (kha)</td><td>Kiga (cgg)</td></tr><tr><td>Kikuyu (ki)</td><td>Kiluba (Luba-Katanga) (lu)</td><td>Kinyarwanda (rw)</td><td>Kituba (DRC) (ktu)</td></tr><tr><td>Kokborok (trp)</td><td>Komi (kv)</td><td>Kongo (kg)</td><td>Korean (ko)</td></tr><tr><td>Krio (kri)</td><td>Kumaoni (kfy)</td><td>Kurdish (Sorani) (ckb)</td><td>Kurukh (kru)</td></tr><tr><td>Lahnda Punjabi (Pakistan) (pa-Arab)</td><td>Latgalian (ltg)</td><td>Lepcha (lep)</td><td>Libyan Arabic (ayl)</td></tr><tr><td>Ligurian (lij)</td><td>Limbu (Limbu script) (lif-Limb)</td><td>Limburgish (li)</td><td>Lingala (ln)</td></tr><tr><td>Lombard (lmo)</td><td>Luganda (lg)</td><td>Luo (luo)</td><td>Madurese (mad)</td></tr><tr><td>Magahi (mag)</td><td>Maithili (mai)</td><td>Makassar (mak)</td><td>Malagasy (mg)</td></tr><tr><td>Malay (Jawi Script) (ms-Arab)</td><td>Mam (mam)</td><td>Mandeali (mil)</td><td>Manx (gv)</td></tr><tr><td>Mapudungun (arn)</td><td>Marshallese (mh)</td><td>Marwadi (mwr)</td><td>Mauritian Creole (mfe)</td></tr><tr><td>Meadow Mari (chm)</td><td>Meiteilon (Manipuri) (mni-Mtei)</td><td>Mewari (mtr)</td><td>Minang (min)</td></tr><tr><td>Mizo (lus)</td><td>Modern Standard Arabic (ar)</td><td>Moor00e9 (mos)</td><td>Morrocan Arabic (ar-MA)</td></tr><tr><td>Mundari (Devanagari script) (unr-Deva)</td><td>NKo (bm-Nkoo)</td><td>Navajo (nv)</td><td>Ndau (ndc-ZW)</td></tr><tr><td>Nepalbasa (Newari) (new)</td><td>Nepali (ne)</td><td>Nigerian Pidgin (pcm)</td><td>Nimadi (noe)</td></tr><tr><td>North Levantine Arabic (apc)</td><td>North Ndebele (nd)</td><td>Northern Sami (se)</td><td>Nuer (nus)</td></tr><tr><td>Occitan (oc)</td><td>Oromo (om)</td><td>Ossetian (os)</td><td>Pangasinan (pag)</td></tr><tr><td>Papiamento (pap)</td><td>Polish (pl)</td><td>Q&#x27;eqchi&#x27; (kek)</td><td>Quechua (qu)</td></tr><tr><td>Rohingya (Latin script) (rhg-Latn)</td><td>Romani (rom)</td><td>Rundi (rn)</td><td>Russian (ru)</td></tr><tr><td>Sambalpuri (spv)</td><td>Sango (sg)</td><td>Sanskrit (sa)</td><td>Santali (Latin Script) (sat-Latn)</td></tr><tr><td>Saralki (skr)</td><td>Sepedi (nso)</td><td>Sesotho (st)</td><td>Seychellois Creole (crs)</td></tr><tr><td>Shan (shn)</td><td>Sherpa (Tibetan script) (xsr-Tibt)</td><td>Shina (sci)</td><td>Shona (sn)</td></tr><tr><td>Sicilian (scn)</td><td>Silesian (szl)</td><td>Sindhi (Devanagari script) (sd-Deva)</td><td>Somali (so)</td></tr><tr><td>South Ndebele (nr)</td><td>Spanish (es)</td><td>Sudanese Arabic (Deprecated BCP) (apd)</td><td>Surgujia (sgj)</td></tr><tr><td>Surjapuri (sjp)</td><td>Susu (sus)</td><td>Swahili (sw)</td><td>Swati (ss)</td></tr><tr><td>Sylheti (syl)</td><td>Tahitian (ty)</td><td>Tamazight (Latin Script) (ber-Latn)</td><td>Tamazight (Tifinagh Script) (ber)</td></tr><tr><td>Tetum (tet)</td><td>Thai (th)</td><td>Tibetan (bo)</td><td>Tigrinya (ti)</td></tr><tr><td>Tiv (tiv)</td><td>Tok Pisin (tpi)</td><td>Tonga (Tonga Islands) (to)</td><td>Tsonga (ts)</td></tr><tr><td>Tswana (tn)</td><td>Tulu (tcy)</td><td>Tumbuka (tum)</td><td>Tunisian Arabic (aeb)</td></tr><tr><td>Turkish (tr)</td><td>Tuvan (tyv)</td><td>Twi (ak)</td><td>Udmurt (udm)</td></tr><tr><td>Venda (ve)</td><td>Venetian (vec)</td><td>Vietnamese (vi)</td><td>Wagdi (wbr)</td></tr><tr><td>Waray (Philippines) (war)</td><td>West Circassian (ady)</td><td>Wolof (wo)</td><td>Xhosa (xh)</td></tr><tr><td>Yakut (sah)</td><td>Yoruba (yo)</td><td>Yucatec Maya (yua)</td><td>Zapotec (zap)</td></tr></table></div>
<p class="figure_title" style="text-align: center;">Bảng 6 | Các ngôn ngữ có nguồn gốc từ tiếng Anh</p>
<div class="table-container"><table><tr><td>Albanian (sq)</td><td>Arabic (Egypt) (ar-EG)</td><td>Armenian (hy)</td><td>Bangla (bn)</td><td>Basque (eu)</td></tr><tr><td>Belarusian (be)</td><td>Bosnian (bs)</td><td>Bulgarian (bg)</td><td>Burmese (my)</td><td>Catalan (ca)</td></tr><tr><td>Chinese (Taiwan) (zh-TW)</td><td>Corsican (co)</td><td>Croatian (hr)</td><td>Czech (cs)</td><td>Danish (da)</td></tr><tr><td>Estonian (et)</td><td>Filipino (fil)</td><td>Finnish (fi)</td><td>French (Canada) (fr-CA)</td><td>Galician (gl)</td></tr><tr><td>Greek (el)</td><td>Gujarati (gu)</td><td>Haitian Creole (ht)</td><td>Hawaiian (haw)</td><td>Hebrew (he)</td></tr><tr><td>Hmong (hmn)</td><td>Hungarian (hu)</td><td>Icelandic (is)</td><td>Inuktut (Latin) (iu-Latn)</td><td>Irish (ga)</td></tr><tr><td>Javanese (jv)</td><td>Kannada (kn)</td><td>Kazakh (kk)</td><td>Khmer (km)</td><td>Kyrgyz (ky)</td></tr><tr><td>Lao (lo)</td><td>Latvian (lv)</td><td>Lithuanian (lt)</td><td>Luxembourgish (lb)</td><td>Macedonian (mk)</td></tr><tr><td>Malay (ms)</td><td>Malayalam (ml)</td><td>Maltese (mt)</td><td>Marathi (mr)</td><td>Mongolian (mn)</td></tr><tr><td>Norwegian (no)</td><td>Persian (fa)</td><td>Portuguese (Brazil) (pt-BR)</td><td>Portuguese (Portugal) (pt-PT)</td><td>Punjabi (pa)</td></tr><tr><td>Romanian (ro)</td><td>Samoan (sm)</td><td>Santali (Ol Chiki script) (sat)</td><td>Scottish Gaelic (gd)</td><td>Serbian (Cyrillic) (sr-Cyrl)</td></tr><tr><td>Serbian (Latin) (sr-Latn)</td><td>Sinhala (si)</td><td>Slovak (sk)</td><td>Slovenian (sl)</td><td>Sundanese (su)</td></tr><tr><td>Swahili (Kenya) (sw-KE)</td><td>Swahili (Tanzania) (sw-TZ)</td><td>Swedish (sv)</td><td>Tajik (tg)</td><td>Tamil (ta)</td></tr><tr><td>Telugu (te)</td><td>Tshiluba (Luba-Lulua) (lua)</td><td>Ukrainian (uk)</td><td>Urdu (ur)</td><td>Uyghur (ug)</td></tr></table></div>
<p class="figure_title" style="text-align: center;">Bảng 7 | Các cặp ngôn ngữ không phải tiếng Anh</p>
<div class="table-container"><table><tr><td>Amharic (am)↔Arabic (ar)</td><td>Amharic (am)↔Mandarin Chinese (zh)</td><td>Arabic (ar)↔Swahili (sw)</td></tr><tr><td>Cantonese (yue)↔Mandarin Chinese (zh)</td><td>Cantonese (yue)↔Taiwanese Mandarin (zh-Hant)</td><td>Chinese (zh-CN)→Japanese (ja)</td></tr><tr><td>Czech (cs)→German (de)</td><td>Czech (cs)→Ukrainian (uk)</td><td>Mandarin Chinese (zh)↔Swahili (sw)</td></tr></table></div>
</div>
</body></html>