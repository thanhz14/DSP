### 1. Introduction

As the primary repository of human knowledge, documents are growing exponentially in both volume and complexity, establishing document parsing as a pivotal technology in the era of artificial intelligence. The ultimate objective of document parsing [1,2,3,4] extends beyond mere text recognition; it aims to reconstruct the deep structural and semantic layout of a document. By meticulously distinguishing text blocks, decoding complex formulas and tables, and deducing the logical reading order, advanced parsing lays the groundwork for Large Language Models (LLMs) [5,6,7]. Crucially, this capability empowers Retrieval-Augmented Generation (RAG) systems [8] to ingest high-fidelity knowledge, thereby enhancing their reliability in downstream applications.

The field has witnessed a surge of innovation following October 2025, with several significant document parsing solutions emerging to push the boundaries of document intelligence. Notably, PaddleOCR-VL [9] established a high performance baseline, surpassing contemporary SOTA metrics with only 0.9 billion parameters and demonstrating strong multi-scenario generalization. Concurrently, DeepSeek-OCR [10] leverages an optical 2D mapping methodology to enable high-ratio vision-to-text compression, offering robust end-to-end parsing capabilities. MonkeyOCR v1.5 [11] further enhances the three-stage parsing framework, while HunyuanOCR [12] extends expert OCR capabilities through a unified architecture supporting translation and extraction.

Despite these advancements, a critical gap remains: most existing models are primarily optimized for "digital-born" or cleanly scanned documents. Real-world scenarios involving extreme physical distortions—such as aggressive skewing, non-rigid warping of pages, screen-capture moiré patterns, and erratic lighting—remain significant hurdles that even state-of-the-art solutions have yet to fully overcome.

To bridge this gap, we present PaddleOCR-VL-1.5, a high-performance, resource-efficient document parsing solution that significantly enhances both general precision and real-world robustness. Building upon the proven 0.9B ultra-compact architecture, PaddleOCR-VL-1.5 introduces several critical advancements:

• Firstly, we upgrade the layout engine to PP-DocLayoutV3. Unlike previous Layout Analysis methods (e.g., Dolphin [3], MinerU2.5 [2], or even PP-DocLayoutV2 [13]), PP-DocLayoutV3 is specifically engineered to handle non-planar document images. It can directly predict multi-point bounding boxes for layout elements—as opposed to standard two-point boxes—and determine logical reading orders for skewed and warped surfaces within a single forward pass, significantly reducing cascading errors.

- Secondly, we expand the model's core capabilities. While maintaining the efficient NaViT-style dynamic resolution encoder and the ERNIE-4.5-0.3B [5] language backbone, we have integrated new tasks including seal recognition and text spotting. Systematic optimizations in text, table, and formula recognition have further propelled the model to a new performance milestone.

- Thirdly, we construct Real5-OmniDocBench to evaluate in-the-wild robustness. Recognizing the lack of benchmarks for physical distortions, we curated this dataset based on OmniDocBench v1.5 [14]. It comprises five distinct scenarios: scanning, warping, screen photography, illumination, and skew. By maintaining a strict one-to-one correspondence with the original ground-truth annotations, Real5-OmniDocBench serves as a rigorous benchmark for assessing model resilience in practical applications.

Comprehensive benchmarking confirms that PaddleOCR-VL-1.5 establishes a new state-