### B. Details of the Real5-OmniDocBench Benchmark

Real5-OmniDocBench $ ^{2} $ is a brand-new benchmark oriented toward real-world scenarios, which we constructed based on the OmniDocBench v1.5 [14] dataset. PaddleOCR-VL-1.5 achieves state-of-the-art (SOTA) results across all sub-scenarios within Real5-OmniDocBench, demonstrating its robust parsing capabilities for real-world documents. A detailed comparison of PaddleOCR-VL-1.5 against other advanced document parsing models across various metrics on this dataset is provided in this Appendix.

As shown in Table A2, under the scanning scenario, PaddleOCR-VL-1.5 achieves state-of-the-art performance across all key metrics, consistently outperforming existing pipeline tools, general vision-language models, and specialized document parsing models. Compared to its predecessor, PaddleOCR-VL, the new version maintains a compact parameter size of 0.9B while raising the overall score from 92.11% to a leading 93.43%. Notably, PaddleOCR-VL-1.5 sets new records in all sub-tasks within this scenario, including a Formula-CDM score of 93.04% and a Table-TEDS score of 90.97%, both significantly surpassing larger models such as Qwen3-VL-235B and Gemini-3 Pro. Additionally, the model achieves exceptionally low Text-Edit Distance (0.037) and Reading Order score (0.045), further demonstrating its high accuracy in text recognition, formula extraction, and complex table structure analysis. Overall, PaddleOCR-VL-1.5 delivers a new breakthrough in the Real5-OmniDocBench-scaning scenario.


<table border=1 style='margin: auto; word-wrap: break-word;'><tr><td style='text-align: center; word-wrap: break-word;'>Model Type</td><td style='text-align: center; word-wrap: break-word;'>Methods</td><td style='text-align: center; word-wrap: break-word;'>Parameters</td><td style='text-align: center; word-wrap: break-word;'>Overall $ \uparrow $</td><td style='text-align: center; word-wrap: break-word;'>TextEdit $ \downarrow $</td><td style='text-align: center; word-wrap: break-word;'>FormulaCDM $ \uparrow $</td><td style='text-align: center; word-wrap: break-word;'>TableTEDS $ \uparrow $</td><td style='text-align: center; word-wrap: break-word;'>Reading OrderEdit $ \downarrow $</td></tr><tr><td rowspan="2">Pipeline Tools</td><td style='text-align: center; word-wrap: break-word;'>Maker-1.8.2 [24]</td><td style='text-align: center; word-wrap: break-word;'>-</td><td style='text-align: center; word-wrap: break-word;'>70.27</td><td style='text-align: center; word-wrap: break-word;'>0.223</td><td style='text-align: center; word-wrap: break-word;'>77.03</td><td style='text-align: center; word-wrap: break-word;'>56.05</td><td style='text-align: center; word-wrap: break-word;'>0.238</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>PP-StructureV3 [22]</td><td style='text-align: center; word-wrap: break-word;'>-</td><td style='text-align: center; word-wrap: break-word;'>84.68</td><td style='text-align: center; word-wrap: break-word;'>0.094</td><td style='text-align: center; word-wrap: break-word;'>84.34</td><td style='text-align: center; word-wrap: break-word;'>79.06</td><td style='text-align: center; word-wrap: break-word;'>0.092</td></tr><tr><td rowspan="5">General VLMs</td><td style='text-align: center; word-wrap: break-word;'>GPT-5.2 [28]</td><td style='text-align: center; word-wrap: break-word;'>-</td><td style='text-align: center; word-wrap: break-word;'>84.43</td><td style='text-align: center; word-wrap: break-word;'>0.142</td><td style='text-align: center; word-wrap: break-word;'>85.68</td><td style='text-align: center; word-wrap: break-word;'>81.78</td><td style='text-align: center; word-wrap: break-word;'>0.109</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Qwen2.5-VL-72B [29]</td><td style='text-align: center; word-wrap: break-word;'>72B</td><td style='text-align: center; word-wrap: break-word;'>86.19</td><td style='text-align: center; word-wrap: break-word;'>0.110</td><td style='text-align: center; word-wrap: break-word;'>86.14</td><td style='text-align: center; word-wrap: break-word;'>83.41</td><td style='text-align: center; word-wrap: break-word;'>0.114</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Gemini-2.5 Pro [30]</td><td style='text-align: center; word-wrap: break-word;'>-</td><td style='text-align: center; word-wrap: break-word;'>89.25</td><td style='text-align: center; word-wrap: break-word;'>0.073</td><td style='text-align: center; word-wrap: break-word;'>87.44</td><td style='text-align: center; word-wrap: break-word;'>87.62</td><td style='text-align: center; word-wrap: break-word;'>0.098</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Qwen3-VL-235B-A22B-Instruct [29]</td><td style='text-align: center; word-wrap: break-word;'>235B</td><td style='text-align: center; word-wrap: break-word;'>89.43</td><td style='text-align: center; word-wrap: break-word;'>0.059</td><td style='text-align: center; word-wrap: break-word;'>89.01</td><td style='text-align: center; word-wrap: break-word;'>85.19</td><td style='text-align: center; word-wrap: break-word;'>0.066</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Gemini-3 Pro [15]</td><td style='text-align: center; word-wrap: break-word;'>-</td><td style='text-align: center; word-wrap: break-word;'>89.47</td><td style='text-align: center; word-wrap: break-word;'>0.071</td><td style='text-align: center; word-wrap: break-word;'>88.16</td><td style='text-align: center; word-wrap: break-word;'>87.37</td><td style='text-align: center; word-wrap: break-word;'>0.078</td></tr><tr><td rowspan="12">Specialized VLMs</td><td style='text-align: center; word-wrap: break-word;'>Dolphin [3]</td><td style='text-align: center; word-wrap: break-word;'>322M</td><td style='text-align: center; word-wrap: break-word;'>72.16</td><td style='text-align: center; word-wrap: break-word;'>0.154</td><td style='text-align: center; word-wrap: break-word;'>64.58</td><td style='text-align: center; word-wrap: break-word;'>67.27</td><td style='text-align: center; word-wrap: break-word;'>0.130</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Dolphin-1.5 [3]</td><td style='text-align: center; word-wrap: break-word;'>0.3B</td><td style='text-align: center; word-wrap: break-word;'>83.39</td><td style='text-align: center; word-wrap: break-word;'>0.097</td><td style='text-align: center; word-wrap: break-word;'>76.25</td><td style='text-align: center; word-wrap: break-word;'>83.65</td><td style='text-align: center; word-wrap: break-word;'>0.090</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>MinerU2-VLM [25]</td><td style='text-align: center; word-wrap: break-word;'>0.9B</td><td style='text-align: center; word-wrap: break-word;'>83.60</td><td style='text-align: center; word-wrap: break-word;'>0.094</td><td style='text-align: center; word-wrap: break-word;'>79.76</td><td style='text-align: center; word-wrap: break-word;'>80.44</td><td style='text-align: center; word-wrap: break-word;'>0.091</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>MonkeyOCR-pro-1.2B [1]</td><td style='text-align: center; word-wrap: break-word;'>1.9B</td><td style='text-align: center; word-wrap: break-word;'>84.64</td><td style='text-align: center; word-wrap: break-word;'>0.123</td><td style='text-align: center; word-wrap: break-word;'>84.17</td><td style='text-align: center; word-wrap: break-word;'>82.13</td><td style='text-align: center; word-wrap: break-word;'>0.145</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>MonkeyOCR-3B [1]</td><td style='text-align: center; word-wrap: break-word;'>3.7B</td><td style='text-align: center; word-wrap: break-word;'>84.65</td><td style='text-align: center; word-wrap: break-word;'>0.100</td><td style='text-align: center; word-wrap: break-word;'>84.16</td><td style='text-align: center; word-wrap: break-word;'>79.81</td><td style='text-align: center; word-wrap: break-word;'>0.143</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Nanonets-OCR-s [34]</td><td style='text-align: center; word-wrap: break-word;'>3B</td><td style='text-align: center; word-wrap: break-word;'>85.52</td><td style='text-align: center; word-wrap: break-word;'>0.106</td><td style='text-align: center; word-wrap: break-word;'>88.09</td><td style='text-align: center; word-wrap: break-word;'>79.11</td><td style='text-align: center; word-wrap: break-word;'>0.106</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Deepseek-OCR [10]</td><td style='text-align: center; word-wrap: break-word;'>3B</td><td style='text-align: center; word-wrap: break-word;'>86.17</td><td style='text-align: center; word-wrap: break-word;'>0.078</td><td style='text-align: center; word-wrap: break-word;'>83.59</td><td style='text-align: center; word-wrap: break-word;'>82.69</td><td style='text-align: center; word-wrap: break-word;'>0.085</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>dots.ocr [35]</td><td style='text-align: center; word-wrap: break-word;'>3B</td><td style='text-align: center; word-wrap: break-word;'>86.87</td><td style='text-align: center; word-wrap: break-word;'>0.083</td><td style='text-align: center; word-wrap: break-word;'>83.27</td><td style='text-align: center; word-wrap: break-word;'>85.68</td><td style='text-align: center; word-wrap: break-word;'>0.081</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>MonkeyOCR-pro-3B [1]</td><td style='text-align: center; word-wrap: break-word;'>3.7B</td><td style='text-align: center; word-wrap: break-word;'>86.94</td><td style='text-align: center; word-wrap: break-word;'>0.103</td><td style='text-align: center; word-wrap: break-word;'>86.29</td><td style='text-align: center; word-wrap: break-word;'>84.86</td><td style='text-align: center; word-wrap: break-word;'>0.141</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>MinerU2.5 [2]</td><td style='text-align: center; word-wrap: break-word;'>1.2B</td><td style='text-align: center; word-wrap: break-word;'>90.06</td><td style='text-align: center; word-wrap: break-word;'>0.052</td><td style='text-align: center; word-wrap: break-word;'>88.22</td><td style='text-align: center; word-wrap: break-word;'>87.16</td><td style='text-align: center; word-wrap: break-word;'>0.050</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>PaddleOCR-VL [9]</td><td style='text-align: center; word-wrap: break-word;'>0.9B</td><td style='text-align: center; word-wrap: break-word;'>92.11</td><td style='text-align: center; word-wrap: break-word;'>0.039</td><td style='text-align: center; word-wrap: break-word;'>90.35</td><td style='text-align: center; word-wrap: break-word;'>89.90</td><td style='text-align: center; word-wrap: break-word;'>0.048</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>PaddleOCR-VL-1.5</td><td style='text-align: center; word-wrap: break-word;'>0.9B</td><td style='text-align: center; word-wrap: break-word;'>93.43</td><td style='text-align: center; word-wrap: break-word;'>0.037</td><td style='text-align: center; word-wrap: break-word;'>93.04</td><td style='text-align: center; word-wrap: break-word;'>90.97</td><td style='text-align: center; word-wrap: break-word;'>0.045</td></tr></table>

<div style="text-align: center;">Table A2 | Comprehensive evaluation of document parsing on Real5-OmniDocBench-scaning</div>


As shown in Table A3, PaddleOCR-VL-1.5 exhibits notable robustness in the warping scenario, achieving an overall score of 91.25%, which is higher than the larger Qwen3-VL-235B model (89.99%). Its Formula-CDM score of 90.94% and Table-TEDS score of 88.10% indicate a strong ability to preserve document structure under significant geometric distortion.