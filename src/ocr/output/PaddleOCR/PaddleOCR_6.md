##### 2.2.1. Layout Analysis

The training of PP-DocLayoutV3 evolves from the two-stage decoupled process used in PP-DocLayoutV2 [9] to a more sophisticated end-to-end joint optimization strategy. This approach allows the detection, instance segmentation, and reading order modules to share a unified feature representation, leading to better alignment between spatial localization and logical sequencing.

The model is initialized with the pre-trained weights of PP-DocLayout_plus-L [13], we scaled our training corpus to over 38k high-quality document samples. Each sample underwent rigorous manual annotation to provide ground truth, include the coordinates, categorical label and absolute reading order for every layout elements.

To achieve the environmental robustness, we designed a specialized Distortion-Aware Data Augmentation pipeline. Unlike standard augmentations, this pipeline specifically simulates complex physical deformations found in real-world mobile photography.

We utilize the AdamW optimizer with a weight decay of 0.0001. The learning rate is set to a constant  $ 2 \times 10^{-4} $ to ensure stable convergence of the integrated Global Pointer and Mask heads. The model is trained for 150 epochs with a total batch size of 32.

In contrast to the previous version, all components—including the RT-DETR backbone and the integrated reading order transformer—are trained simultaneously. This end-to-end supervision ensures that the learned queries in the Transformer decoder capture both the geometric boundaries and the topological relationships of the document elements.

##### 2.2.2. Element-level Recognition and Text Spotting

Building upon the architecture described in Section 2.1.2, PaddleOCR-VL-1.5-0.9B introduces a progressive training paradigm using PaddleFormers [18], which is a high-performance training toolkit for LLMs and VLMs built on the PaddlePaddle framework [19]. While we retain the effective post-adaptation strategy and initialization settings from our previous version, the training methodology has been significantly upgraded to enhance data scale, task diversity, and model robustness. The overview of the three stages is presented in Table 1.


<table border=1 style='margin: auto; word-wrap: break-word;'><tr><td style='text-align: center; word-wrap: break-word;'>Settings</td><td style='text-align: center; word-wrap: break-word;'>Pre-training</td><td style='text-align: center; word-wrap: break-word;'>Post-training</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Training Samples</td><td style='text-align: center; word-wrap: break-word;'>46M</td><td style='text-align: center; word-wrap: break-word;'>5.6M</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Max Resolution</td><td style='text-align: center; word-wrap: break-word;'>1280  $ \times $ 28  $ \times $ 28</td><td style='text-align: center; word-wrap: break-word;'>1280  $ \times $ 28  $ \times $ 28</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Sequence length</td><td style='text-align: center; word-wrap: break-word;'>16384</td><td style='text-align: center; word-wrap: break-word;'>16384</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Trainable components</td><td style='text-align: center; word-wrap: break-word;'>All</td><td style='text-align: center; word-wrap: break-word;'>All</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Batch sizes</td><td style='text-align: center; word-wrap: break-word;'>128</td><td style='text-align: center; word-wrap: break-word;'>128</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Data Augmentation</td><td style='text-align: center; word-wrap: break-word;'>Yes</td><td style='text-align: center; word-wrap: break-word;'>Yes</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Maximum LR</td><td style='text-align: center; word-wrap: break-word;'>5  $ \times $ 10 $ ^{-5} $</td><td style='text-align: center; word-wrap: break-word;'>8  $ \times $ 10 $ ^{-6} $</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>Epoch</td><td style='text-align: center; word-wrap: break-word;'>1</td><td style='text-align: center; word-wrap: break-word;'>1</td></tr></table>

<div style="text-align: center;">Table 1 | Training settings for PaddleOCR-VL-1.5-0.9B.</div>


Pre-training: Enhanced Vision-Language Alignment. While the fundamental objective remains aligning visual features with textual semantics, this stage undergoes a substantial data upgrade compared to PaddleOCR-VL-0.9B [9], scaling the pre-training dataset from 29 million to 46 million image-text pairs. This expansion represents a qualitative leap in data distribution rather than a mere quantitative increase. Specifically, to enhance the generalization of the visual backbone and support the newly introduced capabilities, we incorporate a broader spectrum of multilingual documents and complex real-world scenarios. Furthermore, we intentionally inject