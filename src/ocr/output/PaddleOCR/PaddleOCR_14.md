converting PDF pages into images), layout analysis, and VLM inference. Each stage runs in its own dedicated thread, and intermediate results are exchanged between adjacent stages via queue-based buffers. This pipelined architecture enables concurrent execution across stages, thereby increasing parallelism and improving overall throughput. For the VLM inference stage in particular, mini-batches are formed dynamically: a batch is launched either when the queue size reaches a preset capacity or when the oldest queued item has waited longer than a specified time limit. This batching strategy makes it possible to group content blocks from multiple pages into a single inference call, which substantially increases parallel efficiency, especially when processing large collections of documents. In addition, we deploy PaddleOCR-VL-1.5-0.9B on high-performance inference and serving frameworks, i.e., FastDeploy [37], vLLM [38], and SGLang [39]. Key runtime parameters, including max-num-batched-tokens and gpu-memory-utilization, are carefully tuned to strike a balance between maximizing inference throughput and controlling GPU memory usage.

Table 6 summarizes the end-to-end inference efficiency of different OCR methods under various deployment backends on the OmniDocBench v1.5 dataset. PaddleOCR-VL-1.5 achieves the best overall performance across all metrics. With the FastDeploy backend, it reaches 1.4335 pages/s and 2016.6 tokens/s on a single NVIDIA A100 GPU, surpassing its predecessor PaddleOCR-VL by 16.9% and 18.6%, respectively. These results verify that PaddleOCR-VL-1.5 provides state-of-the-art inference speed and throughput, making it well-suited for large-scale, real-world document understanding applications.


<table border=1 style='margin: auto; word-wrap: break-word;'><tr><td style='text-align: center; word-wrap: break-word;'>Methods</td><td style='text-align: center; word-wrap: break-word;'>Backend</td><td style='text-align: center; word-wrap: break-word;'>Total Time (s) $ \downarrow $</td><td style='text-align: center; word-wrap: break-word;'>Pages/s $ \uparrow $</td><td style='text-align: center; word-wrap: break-word;'>Tokens/s $ \uparrow $</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>MonkeyOCR-pro-1.2B [1]</td><td style='text-align: center; word-wrap: break-word;'>vLLM (v0.10.2)</td><td style='text-align: center; word-wrap: break-word;'>2152.7</td><td style='text-align: center; word-wrap: break-word;'>0.6292</td><td style='text-align: center; word-wrap: break-word;'>949.8</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>dots.ocr [35]</td><td style='text-align: center; word-wrap: break-word;'>vLLM (v0.14.0)</td><td style='text-align: center; word-wrap: break-word;'>3236.2</td><td style='text-align: center; word-wrap: break-word;'>0.2791</td><td style='text-align: center; word-wrap: break-word;'>374.3</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>MinerU2.5 (mineru=2.5.2) [2]</td><td style='text-align: center; word-wrap: break-word;'>vLLM (v0.10.2)</td><td style='text-align: center; word-wrap: break-word;'>1356.5</td><td style='text-align: center; word-wrap: break-word;'>0.9984</td><td style='text-align: center; word-wrap: break-word;'>1415.1</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>DeepSeek-OCR [10]</td><td style='text-align: center; word-wrap: break-word;'>vLLM (v0.8.5)</td><td style='text-align: center; word-wrap: break-word;'>2130.5</td><td style='text-align: center; word-wrap: break-word;'>0.6358</td><td style='text-align: center; word-wrap: break-word;'>897.4</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>PaddleOCR-VL</td><td style='text-align: center; word-wrap: break-word;'>vLLM (v0.10.2)</td><td style='text-align: center; word-wrap: break-word;'>1325.5</td><td style='text-align: center; word-wrap: break-word;'>1.0216</td><td style='text-align: center; word-wrap: break-word;'>1419.9</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>PaddleOCR-VL</td><td style='text-align: center; word-wrap: break-word;'>FastDeploy (v2.3)</td><td style='text-align: center; word-wrap: break-word;'>1104.5</td><td style='text-align: center; word-wrap: break-word;'>1.2261</td><td style='text-align: center; word-wrap: break-word;'>1700.5</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>PaddleOCR-VL-1.5</td><td style='text-align: center; word-wrap: break-word;'>vLLM (v0.10.2)</td><td style='text-align: center; word-wrap: break-word;'>1184.3</td><td style='text-align: center; word-wrap: break-word;'>1.1433</td><td style='text-align: center; word-wrap: break-word;'>1605.6</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>PaddleOCR-VL-1.5</td><td style='text-align: center; word-wrap: break-word;'>SGLang (v0.5.2)</td><td style='text-align: center; word-wrap: break-word;'>1342.0</td><td style='text-align: center; word-wrap: break-word;'>1.0091</td><td style='text-align: center; word-wrap: break-word;'>1418.9</td></tr><tr><td style='text-align: center; word-wrap: break-word;'>PaddleOCR-VL-1.5</td><td style='text-align: center; word-wrap: break-word;'>FastDeploy (v2.3)</td><td style='text-align: center; word-wrap: break-word;'>944.4</td><td style='text-align: center; word-wrap: break-word;'>1.4335</td><td style='text-align: center; word-wrap: break-word;'>2016.6</td></tr></table>

<div style="text-align: center;">Table 6 | End-to-End Inference Performance Comparison on OmniDocBench v1.5. PDF documents were processed in batches of 512 on a single NVIDIA A100 GPU. The reported end-to-end runtime includes both PDF rendering and Markdown generation. All methods rely</div>


on their built-in PDF parsing modules and default DPI settings to reflect out-of-the-box performance. Tokenization and special processing details follow the protocol introduced in [9].

### 5. Conclusion

This work introduces PaddleOCR-VL-1.5, achieving a record SOTA accuracy of 94.5% on OmniDocBench v1.5 and demonstrating superior general precision in document parsing. A key advancement of this version is its exceptional robustness in unconstrained real-world environments. The model effectively overcomes critical hurdles such as aggressive skewing, non-rigid page warping, and erratic lightingâ€”scenarios where traditional solutions often fail. Furthermore, it expands its functional versatility with the integration of Seal Recognition and Text Spotting. By delivering a high-fidelity data foundation, PaddleOCR-VL-1.5 will significantly enhance the reliability and performance of downstream RAG systems and Large Language Model applications in complex, real-world deployment.