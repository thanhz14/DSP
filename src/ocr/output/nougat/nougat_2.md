<div style="text-align: center;"><img src="imgs/img_in_image_box_139_130_1047_633.jpg" alt="Image" width="76%" /></div>


<div style="text-align: center;">Figure 2: List of the different image augmentation methods used during training on an example snippet form a sample document.</div>


### 3.1 Setup

We render the document images at a resolution of 96 DPI. Due to the restrictive possible input dimensions of the Swin Transformer we choose the input size  $ (H, W) = (896, 672) $. The aspect ratio is in between the US letter and Din A4 format  $ \frac{22}{17} < \frac{4}{3} < \sqrt{2} $. The document images are resized and then padded to achieve the desired input size. This input size allows us to use the Swin base model architecture [30]. We initialize the model with the pre-trained weights. The Transformer decoder has a maximal sequence length of  $ S = 4096 $. This relatively large sizing is due to the fact that the text of academic research papers can be dense and the syntax for tables in particular is token intensive. The BART decoder is a decoder-only transformer with 10 layers. The entire architecture has a total of 350M parameters. We also test experiment with a smaller model (250M parameters) with a slightly smaller sequence length of  $ S = 3584 $ and only 4 decoder layers, where we start from the pre-trained base model.

During inference the text is generated using greedy decoding.

Training We use an AdamW optimizer [34] to train for 3 epochs with an effective batch size of 192. Due to training instabilities, we choose a learning rate of  $  \text{lr}_{\text{init}} = 5 \cdot 10^{-5}  $ which is reduced by a factor of 0.9996 every 15 updates until it reaches  $  \text{lr}_{\text{end}} = 7.5 \cdot 10^{-6}  $.

### 3.2 Data Augmentation

In image recognition tasks, it is often beneficial to use data augmentation to improve generalization. Since we are only using digital-born academic research papers, we need to employ a number of transformations to simulate the imperfections and variability of scanned documents. These transformations include erosion, dilation, gaussian noise, gaussian blur, bitmap conversion, image compression, grid distortion and elastic transform [35]. Each has a fixed probability of being applied to a given image. The transformations are implemented in the Albumentations [36] library. For an overview of the effect of each transformation, see Fig. 2.

During training time, we also add perturbations to the ground truth text by randomly replacing tokens. We found this to reduce the collapse into a repeating loop significantly. For more details, see Section 5.4.